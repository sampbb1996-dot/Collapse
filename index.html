<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" />
  <title>Field + Audio</title>
  <style>
    html,body{margin:0;height:100%;background:#1a1a1a;overflow:hidden}
    canvas{display:block}
    /* only needed to satisfy iOS "user gesture" audio start; disappears after first tap */
    #hint{
      position:fixed; inset:0; display:grid; place-items:center;
      color:#8a8a8a; font:16px/1.2 -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Arial,sans-serif;
      background:rgba(0,0,0,0.0);
      pointer-events:none;
      opacity:1;
      transition:opacity .2s linear;
    }
    #hint.hide{opacity:0}
  </style>
</head>
<body>
  <canvas id="c"></canvas>
  <div id="hint">tap once to enable audio</div>

<script>
(() => {
  // ---------- Visual: field ----------
  const c = document.getElementById('c');
  const ctx = c.getContext('2d', { alpha:false });
  const hint = document.getElementById('hint');

  function resize(){
    c.width = innerWidth;
    c.height = innerHeight;
  }
  addEventListener('resize', resize);
  resize();

  // "Ground state": unbiased (50/50)
  let bias = 0.0;      // ~mean offset (0 is neutral)
  let variance = 0.18; // noise amplitude
  let corr = 0.00;     // spatial correlation (0 = white)
  let corrTarget = 0.00;

  // ---------- Audio: bound to visual statistics ----------
  let audioStarted = false;
  let ac, noiseNode, gainNode, filtNode, panNode, lfo, lfoGain;

  function startAudioOnce(){
    if (audioStarted) return;
    audioStarted = true;
    hint.classList.add('hide');

    ac = new (window.AudioContext || window.webkitAudioContext)();

    // White noise buffer
    const seconds = 2;
    const buf = ac.createBuffer(1, seconds * ac.sampleRate, ac.sampleRate);
    const data = buf.getChannelData(0);
    for (let i=0;i<data.length;i++) data[i] = Math.random()*2-1;

    noiseNode = ac.createBufferSource();
    noiseNode.buffer = buf;
    noiseNode.loop = true;

    // Main chain: noise -> filter -> gain -> pan -> destination
    filtNode = ac.createBiquadFilter();
    filtNode.type = 'lowpass';
    filtNode.frequency.value = 1200;
    filtNode.Q.value = 0.3;

    gainNode = ac.createGain();
    gainNode.gain.value = 0.0; // fade in after start

    panNode = ac.createStereoPanner ? ac.createStereoPanner() : null;

    // very slow LFO to avoid dead-flat sound even at steady state
    lfo = ac.createOscillator();
    lfo.type = 'sine';
    lfo.frequency.value = 0.05;
    lfoGain = ac.createGain();
    lfoGain.gain.value = 80; // small wobble in cutoff
    lfo.connect(lfoGain);
    lfoGain.connect(filtNode.frequency);

    // Connect
    noiseNode.connect(filtNode);
    if (panNode){
      filtNode.connect(gainNode);
      gainNode.connect(panNode);
      panNode.connect(ac.destination);
    } else {
      filtNode.connect(gainNode);
      gainNode.connect(ac.destination);
    }

    noiseNode.start();
    lfo.start();

    // quick fade-in (no "effect", just not jarring)
    const t = ac.currentTime;
    gainNode.gain.setValueAtTime(0.0, t);
    gainNode.gain.linearRampToValueAtTime(0.08, t + 0.15);
  }

  // iOS: must be triggered by gesture
  addEventListener('pointerdown', startAudioOnce, { passive:true, once:true });
  addEventListener('touchstart', startAudioOnce, { passive:true, once:true });

  // ---------- Field evolution (still “noise-like”, but not static) ----------
  // Randomly wander correlation target very slowly; reverts toward zero.
  function driftParams(){
    // tiny random walk on correlation target
    corrTarget += (Math.random()*2-1) * 0.004;
    corrTarget = Math.max(0, Math.min(0.85, corrTarget));
    corr += (corrTarget - corr) * 0.01;

    // bias mean-reverts
    bias *= 0.995;

    // variance mean-reverts (steady)
    variance += (0.18 - variance) * 0.002;
  }

  // One-pole spatial correlation using previous pixel (cheap)
  function render(){
    const w = c.width, h = c.height;
    const img = ctx.createImageData(w, h);
    const d = img.data;

    let prev = 0;
    const a = corr;           // correlation weight
    const b = 1 - a;

    for (let i=0;i<d.length;i+=4){
      // base noise
      const n = (Math.random()*2-1) * variance + bias;
      // correlate
      const v = a*prev + b*n;
      prev = v;

      // map to orange-ish grayscale field
      const base = Math.max(0, Math.min(255, 128 + v*150));
      d[i]   = base;           // R
      d[i+1] = base * 0.78;    // G
      d[i+2] = base * 0.30;    // B
      d[i+3] = 255;
    }

    ctx.putImageData(img, 0, 0);
  }

  // ---------- Bind audio to visual stats ----------
  function bindAudio(){
    if (!audioStarted || !ac) return;

    // Map: correlation -> darker/softer (lower cutoff), variance -> louder/brighter, bias -> pan
    const cutoff = 300 + (1 - corr) * 2400;     // corr↑ => cutoff↓
    const loud   = 0.03 + variance * 0.22;      // variance↑ => louder
    const pan    = Math.max(-1, Math.min(1, bias * 6)); // bias small; exaggerate

    const t = ac.currentTime;
    filtNode.frequency.setTargetAtTime(cutoff, t, 0.05);
    gainNode.gain.setTargetAtTime(loud, t, 0.08);
    if (panNode) panNode.pan.setTargetAtTime(pan, t, 0.08);
  }

  // ---------- Main loop ----------
  function loop(){
    driftParams();
    render();
    bindAudio();
    requestAnimationFrame(loop);
  }
  loop();

})();
</script>
</body>
</html>
